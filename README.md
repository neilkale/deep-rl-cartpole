# Deep RL for OpenAI Cart-Pole Simulation
In the final project, our team (Neil Kale and Keshav Bimbraw) wanted to learn more about applying reinforcement learning to physical systems. We were curious about the OpenAI Gymnasium toolkit for simulations and the recently developed Deep Q-Network algorithm (2015) which we did not study in detail in our graduate artificial intelligence class. To achieve these goals, we tackled the Cart-Pole-v1 simulation provided in OpenAI Gym. The objective of the Cart-Pole simulation is to keep a vertical pole on a rolling cart from falling over.

[![Still frame from our agent for the OpenAI Cart-Pole simulation.](http://img.youtube.com/vi/UjcjXh7-Qp0/0.jpg)](http://www.youtube.com/watch?v=UjcjXh7-Qp0 "CS534 Artificial Intelligence Final Project Clip")

We discovered that both given enough learning time, Q-learning and DQN agents have the capacity to learn the simulation. However DQN appears to learn faster. Further details including our exploration of training hyperparameters and detailed comparisons for various training episode lengths are included in the attached [Final Writeup PDF file](https://github.com/neilkale/deep-rl-cartpole/blob/main/CS%20534%20Final%20Project%20Writeup.pdf).
